{"cells":[{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 파이썬 버전 체크\n","# Check Python Version\n","!python --version"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"03vVx0mDtuwN"},"outputs":[],"source":["# GPU 구성 체크\n","# Check GPU configuration\n","!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# pip 버전 업데이트\n","# Update pip\n","!python3 -m pip install --upgrade pip"]},{"cell_type":"markdown","metadata":{"id":"fwJ-lNbOtp-9"},"source":["#### (2024/09/09) 이 노트북은[Plachtaa](https://github.com/Plachtaa/VITS-fast-fine-tuning)s 노트북의 약간 수정된 버전입니다.  \n","#### (09/09/2024) This notebook is a slightly modified version of [HWcomss](https://github.com/HWcomss)'s notebook, it's working fine now. Many thanks!\n"]},{"cell_type":"markdown","metadata":{},"source":["### STEP 1 환경 구축\n","### STEP 1 (6 min)  \n","#### repository 복제 & 환경 구축  \n","#### Clone repository & Build environment"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-XEdEXyTHVfD"},"outputs":[],"source":["# VITS-fast-fine-tuning 리포지토리를 GitHub에서 클론합니다.\n","# !git clone https://github.com/Plachtaa/VITS-fast-fine-tuning.git\n","# https://{nickname}:{token}@github.com/your-nickname/your-repository.git\n","# !git clone https://Noveled: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@github.com/Noveled/VITS-fast-fine-tuning-min.git\n","\n","!git clone https://github.com/Noveled/VITS-fast-fine-tuning-min.git\n","\n","# 'regex' 패키지를 최신 버전으로 강제 재설치합니다.\n","!python -m pip install --upgrade --force-reinstall regex\n","\n","# 'soundfile' 패키지를 강제로 재설치합니다. 이 패키지는 Python에서 사운드 파일을 처리하는 데 사용됩니다.\n","!python -m pip install --force-reinstall soundfile\n","\n","# 'gradio' 패키지를 강제로 재설치합니다. 이 패키지는 웹 인터페이스에서 머신러닝 및 AI 데모를 구축하는 데 사용됩니다.\n","!python -m pip install --force-reinstall gradio\n","\n","# 'imageio' 패키지의 2.4.1 버전을 설치합니다. 이 패키지는 이미지 읽기 및 쓰기 API를 제공합니다.\n","!python -m pip install imageio==2.4.1\n","\n","# 'youtube-dl' 패키지를 최신 버전으로 업그레이드합니다. YouTube에서 동영상을 다운로드하는 데 사용됩니다.\n","!python -m pip install --upgrade youtube-dl\n","\n","# 'moviepy'를 설치합니다. 이 패키지는 Python에서 동영상 편집을 위한 라이브러리입니다.\n","!python -m pip install moviepy\n","\n","# 현재 작업 디렉터리를 'VITS-fast-fine-tuning-min' 리포지토리로 변경합니다.\n","%cd VITS-fast-fine-tuning-min\n","\n","# 빌드 격리를 사용하지 않고 'requirements.txt' 파일의 의존성을 설치합니다. 이는 빌드 환경 충돌을 피하기 위해 필요합니다.\n","!python -m pip install --no-build-isolation -r requirements.txt\n","\n","# 'numpy' 패키지를 최신 버전으로 업그레이드합니다.\n","!python -m pip install --upgrade numpy\n","\n","# 'numba' 패키지를 업그레이드하고 강제 재설치합니다. 이 패키지는 수치 함수의 고성능 Python 컴파일러입니다.\n","!python -m pip install --upgrade --force-reinstall numba\n","\n","# 'Cython' 패키지를 업그레이드합니다. 이 패키지는 Python 코드를 C로 컴파일하여 속도를 높이는 데 사용됩니다.\n","!python -m pip install --upgrade Cython\n","\n","# 'pyzmq' 패키지를 업그레이드합니다. ZeroMQ의 Python 바인딩으로, 고성능 메시징 라이브러리입니다.\n","!python -m pip install --upgrade pyzmq\n","\n","# 'pydantic' 패키지의 1.10.4 버전을 설치합니다. 이 라이브러리는 Python 타입 어노테이션을 기반으로 한 데이터 검증 및 파싱에 사용됩니다.\n","!python -m pip install pydantic==1.10.4\n","\n","# 'ruamel.yaml' 패키지를 설치합니다. 이 패키지는 YAML 파일을 읽고 쓰는 데 사용됩니다.\n","!python -m pip install ruamel.yaml\n","\n","# OpenAI의 Whisper 패키지를 GitHub에서 설치합니다. Whisper는 음성을 텍스트로 변환하는 모델입니다.\n","!python -m pip install git+https://github.com/openai/whisper.git\n","\n","# Google Drive에서 대용량 파일을 다운로드하는 도구인 'gdown'을 설치합니다.\n","# !python -m pip install gdown\n","\n","# build monotonic align\n","# VITS 실행을 위해 필요한 monotonic align 모듈을 빌드합니다.\n","%cd monotonic_align/\n","\n","# 'monotonic_align' 디렉토리를 생성합니다.\n","!mkdir monotonic_align\n","\n","# monotonic align 확장 모듈을 제자리에 빌드합니다. 이는 VITS 실행에 필수적입니다.\n","!python setup.py build_ext --inplace\n","\n","# 'VITS-fast-fine-tuning-min'의 부모 디렉토리로 다시 이동합니다.\n","%cd ..\n","\n","# 사전 학습된 모델을 저장할 'pretrained_models' 디렉토리를 생성합니다.\n","!mkdir pretrained_models\n","\n","# download data for fine-tuning\n","# 모델을 파인튜닝하기 위한 데이터셋인 'sampled_audio4ft_v2.zip' 파일을 Hugging Face에서 다운로드합니다.\n","!wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/sampled_audio4ft_v2.zip\n","\n","# 다운로드한 데이터셋을 현재 디렉토리로 압축 해제합니다.\n","!unzip sampled_audio4ft_v2.zip\n","\n","# 파인튜닝 과정에서 데이터를 정리할 여러 디렉토리를 생성합니다:\n","# 'video_data' - 비디오 데이터를 저장할 디렉토리,\n","# 'raw_audio' - 원본 오디오 데이터를 저장할 디렉토리,\n","# 'denoised_audio' - 노이즈 제거된 오디오 데이터를 저장할 디렉토리,\n","# 'custom_character_voice' - 파인튜닝에 사용할 사용자 맞춤 음성 파일을 위한 디렉토리,\n","# 'segmented_character_voice' - 과정에서 분할된 음성 데이터를 저장할 디렉토리.\n","!mkdir video_data\n","!mkdir raw_audio\n","!mkdir denoised_audio\n","!mkdir custom_character_voice\n","!mkdir segmented_character_voice\n","\n","# 언어 설정(LC_ALL)과 NVIDIA 라이브러리 경로(LD_LIBRARY_PATH 및 LIBRARY_PATH)를 설정합니다.\n","# 이는 특정 언어 및 CUDA(GPU) 작업을 처리하는 데 필요합니다.\n","!export LC_ALL=\"en_US.UTF-8\"\n","!export LD_LIBRARY_PATH=\"/usr/lib64-nvidia\"\n","!export LIBRARY_PATH=\"/usr/local/cuda/lib64/stubs\"\n","\n","# NVIDIA 라이브러리 경로를 위한 동적 링커 실행 시간 바인딩을 업데이트합니다.\n","!ldconfig /usr/lib64-nvidia"]},{"cell_type":"markdown","metadata":{},"source":["Cython==0.29.21          # Python 코드를 C로 컴파일하여 성능을 높이는 툴.  \n","librosa==0.9.2           # 오디오 및 음악 분석을 위한 Python 라이브러리.  \n","matplotlib==3.3.1        # 데이터 시각화를 위한 Python 플로팅 라이브러리.  \n","scikit-learn==1.0.2      # 머신러닝 알고리즘을 구현한 라이브러리.  \n","scipy                    # 과학 컴퓨팅을 위한 라이브러리. 수학, 과학적 함수 제공.  \n","numpy==1.21.6            # 고성능 수치 계산을 위한 라이브러리. 행렬 및 배열 처리.  \n","tensorboard              # TensorFlow 모델의 학습 과정을 시각화하는 도구.  \n","torch                    # PyTorch 딥러닝 프레임워크. 신경망을 위한 계산 라이브러리.  \n","torchvision              # PyTorch용 컴퓨터 비전 라이브러리. 이미지 처리 기능 제공.  \n","torchaudio               # PyTorch용 오디오 처리 라이브러리.  \n","unidecode                # 유니코드를 ASCII로 변환하는 패키지.  \n","pyopenjtalk-prebuilt     # OpenJTalk 기반의 일본어 음성 합성 라이브러리. 음성 합성에 사용.  \n","jamo                     # 한글 자모 분리 및 처리 라이브러리.  \n","pypinyin                 # 중국어 한자를 핀인(Pinyin)으로 변환해주는 라이브러리.  \n","jieba                    # 중국어 텍스트를 분할하는 텍스트 처리 라이브러리.  \n","protobuf                 # Google의 Protocol Buffers, 구조화된 데이터를 직렬화하기 위한 라이브러리.  \n","cn2an                    # 중국어 숫자를 아라비아 숫자로 변환하는 라이브러리.  \n","inflect                  # 영어 단어의 복수형 변환 등 언어적 처리를 위한 라이브러리.  \n","eng_to_ipa               # 영어를 국제 음성 기호(IPA)로 변환하는 라이브러리.  \n","ko_pron                  # 한국어 발음 변환기. 한국어 문자를 발음 기반으로 변환.  \n","indic_transliteration==2.3.37  # 인도 언어들에 대한 텍스트 변환 및 음성 변환 라이브러리.  \n","num_thai==0.0.5          # 태국어 숫자를 숫자로 변환하는 라이브러리.  \n","opencc==1.1.1            # 중국어 간체와 번체 변환을 위한 라이브러리.  \n","demucs                  # 음성 분리를 위한 딥러닝 기반의 오디오 분리 라이브러리.  \n","git+https://github.com/openai/whisper.git  # Whisper는 OpenAI의 음성 인식 모델.  \n","gradio                  # 머신러닝 모델을 웹 인터페이스로 쉽게 배포하는 도구.  "]},{"cell_type":"markdown","metadata":{"id":"fkx_ago5vhu_"},"source":["## STEP 1.5 사전 훈련 모델 선택  \n","#### STEP 1.5 사전 훈련 모델 선택  \n","#### Choose pretrained model to start  \n","C : 중국어 / J : 일본어 / K : 한국어 / E: 영어 모델 -> CJKE 4개국어 모델 선택  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2tzsb5mR6-d9"},"outputs":[],"source":["PRETRAINED_MODEL = \"CJKE\" # @param [\"CJE\", \"CJ\", \"C\", \"CJKE\"]\n","if PRETRAINED_MODEL == \"CJ\":\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"CJE\":\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"C\":\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json -O ./configs/finetune_speaker.json\n","elif PRETRAINED_MODEL == \"CJKE\":\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth\n","  !wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json\n","  # !gdown --fuzzy https://drive.google.com/file/d/1nwbG7fM5kztBFD-BG2wOcRUF0FUrEFQ3/view?usp=drive_link -O /content/VITS-fast-fine-tuning/scripts/short_audio_transcribe.py\n","  # !gdown --fuzzy https://drive.google.com/file/d/15TUws0mxZqovwHjp3ZjFnD5PTXOMl2sG/view?usp=drive_link -O /content/VITS-fast-fine-tuning/scripts/long_audio_transcribe.py\n","  # !gdown --fuzzy https://drive.google.com/file/d/1_ohqDjFbVJi1upxyJHMUg5kvveHo6oRe/view?usp=drive_link -O /content/VITS-fast-fine-tuning/preprocess_v2.py\n","  # !gdown --fuzzy https://drive.google.com/file/d/19BWvspGUMpw0wIzBLRkJCwKxh_1fvDYo/view?usp=sharing -O /content/VITS-fast-fine-tuning/VC_inference.py"]},{"cell_type":"markdown","metadata":{},"source":["아래 주석 제거하면 사용자 편의 UI 가능해짐"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import ipywidgets as widgets\n","# from IPython.display import display\n","# import os\n","\n","# # 드롭다운 메뉴 생성\n","# pretrained_model = widgets.Dropdown(\n","#     options=[\"CJ\", \"CJE\", \"C\", \"CJKE\"],\n","#     value=\"CJKE\",\n","#     description=\"Model:\"\n","# )\n","\n","# # 선택한 모델에 따라 코드를 실행하는 함수 정의\n","# def download_files(change):\n","#     model = change['new']\n","#     if model == \"CJ\":\n","#         os.system('wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/D_0-p.pth -O ./pretrained_models/D_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/G_0-p.pth -O ./pretrained_models/G_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/sayashi/vits-uma-genshin-honkai/resolve/main/model/config.json -O ./configs/finetune_speaker.json')\n","#     elif model == \"CJE\":\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json')\n","#     elif model == \"C\":\n","#         os.system('wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/D_0.pth -O ./pretrained_models/D_0.pth')\n","#         os.system('wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/G_0.pth -O ./pretrained_models/G_0.pth')\n","#         os.system('wget https://huggingface.co/datasets/Plachta/sampled_audio4ft/resolve/main/VITS-Chinese/config.json -O ./configs/finetune_speaker.json')\n","#     elif model == \"CJKE\":\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/D_trilingual.pth -O ./pretrained_models/D_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/pretrained_models/G_trilingual.pth -O ./pretrained_models/G_0.pth')\n","#         os.system('wget https://huggingface.co/spaces/Plachta/VITS-Umamusume-voice-synthesizer/resolve/main/configs/uma_trilingual.json -O ./configs/finetune_speaker.json')\n","#         os.system('gdown --fuzzy https://drive.google.com/file/d/1nwbG7fM5kztBFD-BG2wOcRUF0FUrEFQ3/view?usp=drive_link -O /content/VITS-fast-fine-tuning/scripts/short_audio_transcribe.py')\n","#         os.system('gdown --fuzzy https://drive.google.com/file/d/15TUws0mxZqovwHjp3ZjFnD5PTXOMl2sG/view?usp=drive_link -O /content/VITS-fast-fine-tuning/scripts/long_audio_transcribe.py')\n","#         os.system('gdown --fuzzy https://drive.google.com/file/d/1_ohqDjFbVJi1upxyJHMUg5kvveHo6oRe/view?usp=drive_link -O /content/VITS-fast-fine-tuning/preprocess_v2.py')\n","#         os.system('gdown --fuzzy https://drive.google.com/file/d/19BWvspGUMpw0wIzBLRkJCwKxh_1fvDYo/view?usp=sharing -O /content/VITS-fast-fine-tuning/VC_inference.py')\n","\n","# # 드롭다운 선택이 변경될 때 실행\n","# pretrained_model.observe(download_files, names='value')\n","\n","# # 드롭다운 메뉴 표시\n","# display(pretrained_model)\n"]},{"cell_type":"markdown","metadata":{},"source":["## STEP 2 캐릭터 오디오 데이터 업로드하기\n","## Upload your character voices\n","데이터 업로드 예시[数据集上传选项](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/DATA.MD)  \n","See [data upload options](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/DATA_EN.MD)  "]},{"cell_type":"markdown","metadata":{"id":"Wjpr__yCPp_J"},"source":["#### STEP 2.1 짧은 오디오 업로드\n","#### Short audio upload"]},{"cell_type":"markdown","metadata":{},"source":["上传选项1：运行该代码块会出现一个文件上传的入口  \n","\n","Upload option 1: Running this code block will prompt you to upload a file.  \n","\n","업로드 옵션 1: 이 코드 블록을 실행하면 파일을 업로드하라는 메시지가 표시됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hmNHnpBL5sgF"},"outputs":[],"source":["%run scripts/voice_upload.py --type zip\n","!unzip ./custom_character_voice/custom_character_voice.zip -d ./custom_character_voice/"]},{"cell_type":"markdown","metadata":{},"source":["上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将`.zip`文件上传云端硬盘后，在下面填写文件路径： \n","  \n","Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. After uploading your `.zip` file to Google drive, fill in the path to your file below:  \n","Google 드라이브를 마운트한 경우 Google 드라이브에서 직접 파일을 로드할 수 있습니다. '.zip' 파일을 Google 드라이브에 업로드한 후 아래 파일 경로를 입력합니다:  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YOfe2ercNLal"},"outputs":[],"source":["ZIP_PATH = \"/content/drive/MyDrive/chune.zip\"  #@param {type:\"string\"}\n","!cp {ZIP_PATH} ./custom_character_voice/custom_character_voice.zip\n","!unzip ./custom_character_voice/custom_character_voice.zip -d ./custom_character_voice/"]},{"cell_type":"markdown","metadata":{"id":"FLGkhbvhP33f"},"source":["#### STEP 2.2 上传长音频 （单个不应长于20分钟）\n","#### Long audio upload\n","#### STEP 2.2 긴 오디오 업로드(단일 20분 이내)"]},{"cell_type":"markdown","metadata":{},"source":["#@markdown 上传选项1：运行该代码块会出现一个文件上传的入口  \n","  \n","#@markdown Upload option 1: Running this code block will prompt you to upload a file.  \n","#이 코드 블록을 실행하면 파일을 업로드하라는 메시지가 표시됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"unvLB7zrQTVA"},"outputs":[],"source":["%run scripts/voice_upload.py --type audio"]},{"cell_type":"markdown","metadata":{},"source":["#@markdown 上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将所有长音频文件上传至云端硬盘的同一个文件夹下，在下面填写文件夹路径： \n","  \n","#@markdown Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. Put all the long audios under one folder, and fill in the path to your folder below:  \n","업로드 옵션 2: Google 드라이브를 마운트한 경우 Google 드라이브에서 직접 파일을 로드할 수 있습니다. 하나의 폴더 아래에 모든 긴 오디오를 넣고 아래 폴더 경로를 입력합니다:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-GWXUozRTZsj"},"outputs":[],"source":["AUDIO_FOLDER_PATH = \"/content/drive/MyDrive/ren\"  #@param {type:\"string\"}\n","!cp {AUDIO_FOLDER_PATH}/* ./raw_audio/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"362TI523iR4N"},"outputs":[],"source":["!rm /content/VITS-fast-fine-tuning/raw_audio/*"]},{"cell_type":"markdown","metadata":{"id":"NYLfZdP9iewu"},"source":[]},{"cell_type":"markdown","metadata":{"id":"uwYv3oXaie89"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZIRIVLDiYW-"},"outputs":[],"source":["!unzip /content/drive/MyDrive/chune.zip -d /content/chune1"]},{"cell_type":"markdown","metadata":{"id":"K4iCi-_SidYv"},"source":[]},{"cell_type":"markdown","metadata":{"id":"5IDg3hAgWY0T"},"source":["#### STEP 2.3 上传视频（单个不应长于20分钟）\n","#### Video upload\n","#### 동영상 업로드(개당 20분 이내)"]},{"cell_type":"markdown","metadata":{},"source":["#@markdown 上传选项1：运行该代码块会出现一个文件上传的入口  \n","  \n","#@markdown Upload option 1: Running this code block will prompt you to upload a file.  \n","#@markdown 업로드 옵션 1: 이 코드 블록을 실행하면 파일을 업로드하라는 메시지가 표시됩니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A4Fk-06bXq7b"},"outputs":[],"source":["%run scripts/voice_upload.py --type video"]},{"cell_type":"markdown","metadata":{},"source":["#@markdown 上传选项2：若您装载了Google云端硬盘，可以直接从Google云端硬盘加载文件。将所有视频文件上传至云端硬盘的同一个文件夹下，在下面填写文件夹路径:  \n","  \n","#@markdown Upload option 2: If you have mounted Google drive, you can load your files from Google drive directly. Put all the videos under one folder, and fill in the path to your folder below:  \n","업로드 옵션 2: Google 드라이브를 마운트한 경우 Google 드라이브에서 직접 파일을 로드할 수 있습니다. 모든 동영상을 하나의 폴더 아래에 넣고 아래 폴더 경로를 입력합니다:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VuDsoW84X3BK"},"outputs":[],"source":["VIDEO_FOLDER_PATH = \"../drive/MyDrive/kane/\"  #@param {type:\"string\"}\n","!cp {VIDEO_FOLDER_PATH}/* ./video_data/"]},{"cell_type":"markdown","metadata":{"id":"n1UxoAnoY8Cp"},"source":["#### STEP 2.4 上传视频链接（单个不应长于20分钟）\n","#### Video link upload\n","#### 영상 링크 업로드(개당 20분 이내)"]},{"cell_type":"markdown","metadata":{},"source":["#@markdown 运行该代码块会出现一个文件上传的入口，上传单个`.txt`文件。若格式正确的话，视频会自动下载并将下载后的文件名打印在下方。\n","\n","#@markdown Running this code block will prompt you to upload a file.  \n","#@markdown Please upload a single `.txt` file. If you have put the links in the correct format,  \n","#@markdown the videos will be automatically downloaded and displayed below.  \n","#@markdown 이 코드 블록을 실행하면 파일을 업로드하라는 메시지가 표시됩니다.  \n","#@markdown '.txt' 파일 하나만 업로드하세요. 링크를 올바른 형식으로 입력했다면,  \n","#@마크다운된 동영상은 아래에 자동으로 다운로드되어 표시됩니다.  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ua_Blt02Cg97"},"outputs":[],"source":["%run scripts/download_video.py\n","!ls ./video_data/"]},{"cell_type":"markdown","metadata":{"id":"YQGC-JyAaD2D"},"source":["## STEP 3 업로드한 모든 데이터 자동 처리"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aJOO7VsPQf3G"},"outputs":[],"source":["# 이 셀을 실행하면 업로드된 모든 데이터에 대해 자동으로 배경음 제거 및 표시가 수행됩니다.\n","# Whisper와 Demucs를 호출해야 하기 때문에 실행 시간이 길어질 수 있습니다.\n","\n","# Running this codeblock will perform automatic vocal seperation & annotation.\n","# 이 코드블록을 실행하면 자동으로 음성 분리 및 라벨링(주석)이 수행됩니다.\n","# Since this step uses Whisper & Demucs, it may take a while to complete.\n","# 이 단계에서는 Whisper & Demucs를 사용하므로 완료하는 데 시간이 걸릴 수 있습니다.\n","\n","# 모든 비디오(업로드든 다운로드든, 반드시. MP4 형식) 오디오 추출\n","%run scripts/video2audio.py\n","# 모든 오디오(업로드든 비디오에서 추출하든, 반드시. wav 형식) 노이즈 제거\n","!python scripts/denoise_audio.py\n","# 긴 오디오를 분할하고 태그하기\n","!python scripts/long_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","# 짧은 오디오 레이블 지정\n","!python scripts/short_audio_transcribe.py --languages \"{PRETRAINED_MODEL}\" --whisper_size large-v2\n","# 베이스 몰드의 샘플링 속도는 보조 데이터와 다를 수 있으므로, 재샘플링이 필요합니다.\n","!python scripts/resample.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAOpp115p_Ue"},"outputs":[],"source":["!zip /content/drive/MyDrive/ren_melotts.zip /content/VITS-fast-fine-tuning/segmented_character_voice/ren/*.wav"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtvRSRjH1Ezz"},"outputs":[],"source":["%cd /content/VITS-fast-fine-tuning-min/segmented_character_voice/ren"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lYlWpZOjqHWS"},"outputs":[],"source":["!cp /content/chune.zip /content/drive/MyDrive/chune1.zip"]},{"cell_type":"markdown","metadata":{"id":"WY12Ien-BUE7"},"source":["#!!! 훈련 품질 관련: 실험 결과 현재 CJ 모델 + 체크 ADD_AUXIARY를 사용하고 있으며, 중/일 평균 훈련에 대해 최고의 효과를 얻을 수 있으며, 첫 번째 훈련에서는 기본 이 조합을 사용하는 것이 좋습니다! ！！"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G_IM97N2e6fk"},"outputs":[],"source":["#@markdown ##STEP 3.5\n","#@markdown 이 셀을 실행하면 트레이닝/테스트 세트를 구분한 최종 표시와 프로필이 생성됩니다.\n","\n","#@markdown 이 블록을 실행하면 교육 및 검증을 위한 최종 주석과 구성 파일이 생성됩니다.\n","\n","#@markdown 보조 훈련 데이터 추가 여부 선택：/ Choose whether to add auxiliary data:\n","ADD_AUXILIARY = True #@param {type:\"boolean\"}\n","#@markdown 보조 훈련 데이터는 사전 훈련된 빅 데이터 세트에서 샘플링하여 얻은 것으로 모델이 부정확하게 표시된 데이터에 잘못된 매핑을 형성하는 것을 방지하는 역할을 합니다.\n","\n","# Auxiliary data is to prevent overfitting when the audio samples are small or with low quality.\n","# 보조 데이터는 오디오 샘플이 작거나 품질이 낮을 때 과적합을 방지하기 위한 것입니다\n","\n","#@markdown 아래의 상황은 체크해 주십시오：\n","\n","#@markdown 총 샘플 수가 100개 미만/ 샘플 품질이 보통이거나 나쁨/ 샘플은 크롤링된 비디오에서 가져옵니다.\n","\n","#@markdown 아래의 상황은 체크하지 않아도 됩니다.：\n","\n","#@markdown 총표본크기/표본크기/훈련 가속화 희망/2차원적 역할만\n","\n","# assert(not (ADD_AUXILIARY and PRETRAINED_MODEL != \"CJE\")), \"add auxiliary data is available only available for CJE model!\"\n","# assert((ADD_AUXIALY 및 사전 훈련된_모델!= \"CJE\"), \"보조 데이터 추가는 CJE 모델에만 사용할 수 있습니다!\"\n","if ADD_AUXILIARY:\n","  %run preprocess_v2.py --add_auxiliary_data True --languages \"{PRETRAINED_MODEL}\"\n","else:\n","  %run preprocess_v2.py --languages \"{PRETRAINED_MODEL}\""]},{"cell_type":"markdown","metadata":{"id":"VA4hV2G_fyKz"},"source":["## STEP 4 훈련 시작"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"4gmpTNtcW2Bt"},"outputs":[],"source":["#@markdown #STEP 4 (>=20 min)\n","#@markdown 모형 미세조정을 시작합니다.\n","#@markdown 훈련 시간은 당신이 입력/업로드한 오디오의 총 수에 따라 다릅니다.\n","\n","#@markdown 사운드 라인과 샘플 품질에 따라 필요한 훈련 epochs의 수도 다릅니다.\n","\n","#@markdown 또한 텐서보드에서 합성 효과를 미리 볼 수 있으며 효과가 만족스러우면 미리 중지할 수 있습니다.\n","\n","#@markdown Model fine-tuning\n","#@markdown Total time cost depends on the number of voices you recorded/uploaded.\n","# 총 시간 비용은 녹음/업로드한 음성 수에 따라 달라집니다.\n","\n","#@markdown Best epoch number varies depending on different uploaded voices / sample quality.\n","# 베스트 에포크 번호는 업로드된 음성/샘플 품질에 따라 달라집니다.\n","\n","#@markdown You can also preview synthezied audio in Tensorboard, it's OK to shut down training manually if you find the quality is satisfying.\n","# 텐서보드에서 합성 오디오를 미리 볼 수도 있으며, 품질이 만족스러우면 교육을 수동으로 종료해도 괜찮습니다.\n","\n","import os\n","# 텐서보드 바이너리 경로 설정 (텐서보드를 사용하기 위한 환경 변수 설정)\n","os.environ['TENSORBOARD_BINARY'] = '/usr/local/bin/tensorboard'\n","\n","# 구글 드라이브 경로가 있는지 확인 (훈련된 데이터를 구글 드라이브에 저장하는 경우)\n","if os.path.exists(\"/content/drive/MyDrive/\"):\n","  # 스피커 임베딩 재구성 스크립트 실행\n","  !python scripts/rearrange_speaker.py\n","  # finetune_speaker.json 파일을 구글 드라이브에 복사 (백업용)\n","  !cp ./finetune_speaker.json ../drive/MyDrive/finetune_speaker.json\n","  # moegoe_config.json 파일을 구글 드라이브에 복사 (백업용)\n","  !cp ./moegoe_config.json ../drive/MyDrive/moegoe_config.json\n","\n","# 텐서보드 확장 프로그램을 리로드\n","%reload_ext tensorboard\n","# 텐서보드 실행 (훈련 로그를 \"./OUTPUT_MODEL\" 경로에서 로드)\n","%tensorboard --logdir \"./OUTPUT_MODEL\"\n","\n","# 최대 에포크 수 설정 (모델이 최대 몇 번의 반복을 학습할지 설정, 기본값은 200)\n","Maximum_epochs = \"200\" #@param {type:\"string\"}\n","\n","# 继续之前的模型训练/Continue training from previous checkpoint\n","# 이전 체크포인트에서 모델 학습을 계속할지 여부 (True이면 이전 체크포인트에서 계속 학습, False이면 새로 학습 시작)\n","# CONTINUE = False이면 새로 학습을 시작하고, True이면 이전 학습 체크포인트에서 이어서 학습함.\n","CONTINUE = False #@param {type:\"boolean\"}\n","\n","# CONTINUE가 True일 경우: 이전 체크포인트에서 학습을 계속\n","if CONTINUE:\n","  # 이전 모델 체크포인트에서 이어서 학습 (최대 에포크 수와 함께 스피커 임베딩 삭제 없이 학습을 이어감)\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed False --cont True\n","else:\n","  # CONTINUE가 False일 경우: 스피커 임베딩을 재설정하고 새로 학습 시작\n","  !python finetune_speaker_v2.py -m \"./OUTPUT_MODEL\" --max_epochs \"{Maximum_epochs}\" --drop_speaker_embed True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mFmb0Jqca8lG"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bbRYuwSAb9ni"},"outputs":[],"source":["!pip install gradio"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SIK2XgD_ckgV"},"outputs":[],"source":["!pip uninstall gradio --yes\n","!pip install gradio==3.50.2\n","#@markdown ### 미세조정이 완료되면 여기서 효과를 시도합니다.\n","#@markdown ### 실행 후 public URL을 출력합니다. 웹 UI 를 클릭하여 모델을 사용합니다\n","#@markdown ### 미세 조정이 끝나면 여기에서 TTS 및 VC 품질을 사용해 보세요.\n","!cp ./configs/modified_finetune_speaker.json ./finetune_speaker.json\n","!python VC_inference.py --model_dir ./OUTPUT_MODEL/G_latest.pth --share True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DfLK9KGVcHX4"},"outputs":[],"source":["!pip uninstall gradio\n","!pip install gradio==3.50.2"]},{"cell_type":"markdown","metadata":{"id":"MXYxSdt-m3YK"},"source":["# STEP 5 모델 다운로드\n","## 로컬 배포 방법은 를 참조하십시오.[README](https://github.com/Plachtaa/VITS-fast-fine-tuning/blob/main/README_ZH.md)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QcJQm6_ImD7o"},"outputs":[],"source":["#@markdown ### 다운로드 옵션 1: 이 셀을 실행하면 브라우저에서 모델과 프로필을 자동으로 다운로드합니다\n","#@markdown ### Download option 1: Running this codeblock will download model & config files by your browser.\n","# 다운로드 옵션 1: 이 코드블록을 실행하면 브라우저에서 모델 및 구성 파일을 다운로드합니다.\n","!python scripts/rearrange_speaker.py\n","%run scripts/download_model.py"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k13JBTommkTj"},"outputs":[],"source":["#@markdown ### 다운로드 옵션 2: 이 셀을 실행하면 모델과 프로필을 Google 클라우드 하드 디스크에 저장합니다\n","#@markdown ### Download option 2: Running this codeblock will save the mode & config files to your Google drive.\n","!mkdir ../drive/MyDrive/MODEL12312\n","!python scripts/rearrange_speaker.py\n","!cp ./G_latest.pth ../drive/MyDrive/MODEL12312/G_latest.pth\n","!cp ./finetune_speaker.json ../drive/MyDrive/MODEL12312/finetune_speaker.json\n","!cp ./moegoe_config.json ../drive/MyDrive/MODEL12312/moegoe_config.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WI67Juj-YXQh"},"outputs":[],"source":["!mkdir /content/drive/MyDrive/MODEL1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hU8LmJlUcF1z"},"outputs":[],"source":["#@markdown ### 运行该单元格会清空所有已上传的样本，需要时可使用\n","# 이 셀을 실행하면 업로드된 샘플이 모두 삭제되며 필요할 때 사용할 수 있습니다.\n","#@markdown ### Running this codeblock will delete all voice samples you have uploaded. Use it if you need.\n","!rm -rf ./custom_character_voice/*\n","!rm -rf ./video_data/*\n","!rm -rf ./raw_audio/*\n","!rm -rf ./denoised_audio/*\n","!rm -rf ./segmented_character_voice/*\n","!rm -rf long_character_anno.txt\n","!rm -rf short_character_anno.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZHK6qw4wRF8T"},"outputs":[],"source":["#@markdown ### 运行该单元格会将切片和标注复制到谷歌云端硬盘根目录下名为`voice_data`的文件夹下以用作其它用途\n","# 3이 셀을 실행하면 슬라이스와 태그가 다른 용도로 구글 클라우드 하드 디스크 루트 아래에 있는 \"voice_data\" 폴더에 복사됩니다.\n","#@markdown ### Running this codeblock will copy all processed voices & annotations to a folder named `voice_data` under the root of Google Drive for other purpose of usage\n","!mkdir ../drive/MyDrive/voice_data/\n","!cp -rf ./custom_character_voice/ ../drive/MyDrive/voice_data/custom_character_voice/\n","!cp -rf ./segmented_character_voice/ ../drive/MyDrive/voice_data/segmented_character_voice/\n","!cp long_character_anno.txt ../drive/MyDrive/voice_data/long_character_anno.txt\n","!cp short_character_anno.txt ../drive/MyDrive/voice_data/short_character_anno.txt"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","private_outputs":true,"provenance":[{"file_id":"1i7TLiaPxcOlBoUiSnARP9MTEBpydmBiG","timestamp":1725842842908}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
